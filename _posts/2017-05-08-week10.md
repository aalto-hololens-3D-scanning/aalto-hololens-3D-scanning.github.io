---
layout: default
title: Week 10 â€“ In-app scan in HoloLens
---
## TL;DR

## Part 1. ([commit]())
This [forum article](https://forums.hololens.com/discussion/comment/8737#Comment_8737) by angela is a good introduction on space data in HoloLens.

> The HoloLens is constantly scanning the environment and saves that data as 'spaces'. Applications can access that data when the 'Spatial Perception' capability is enabled. The information contained in 'spaces' is not directly usable by your Unity application. You need to create game objects with colliders (for physics) and renderers (for visualization) that represent the meshes contained in the 'spaces' file. Some applications will alter the spatial mapping data (blow holes in the mesh, convert them to planes, smooth the mesh, etc.), and you really don't want them doing this to the meshes saved in the 'spaces' file, or else it would negatively impact all other applications that need to use environment data.
When you call SpatialMappingObserver.Start(), you will begin to get Add/Update/Remove events from the observer. If you were to add some Debug.Log() messages to each of these events, you would probably see that the very first time you call Start() you actually get a ton of updates (vs Adds). This is because the HoloLens already knows about the environment (from the 'spaces' file), and is just updating the spatial mapping meshes currently in view with new information. If you were to turn off your HoloLens and then venture to a new area before restarting your app, then you would probably see a lot more 'Add' events after the initial .Start() call. Unfortunately, you cannot guarantee that the user has scanned their environment before running your application, or that the current 'spaces' file contains enough data to be useful to your application. This is where scanning becomes important to your application.

> The HoloLens' knowledge of the room is constantly changing. Objects in the room can move around, and meshes will get more refined as users move closer to real-world surfaced (best scan results occur ~0.8-2m from a surface). To get the most up-to-date version of the mesh, it's good practice to have the user scan their area first. While you can certainly do this outside of your application (the user just needs to walk around while wearing the HoloLens), there is no guarantee that the user will actually take the time to do so. By providing a built-in scanning experience, you can ensure that the user has scanned their area and you can also do some processing of the mesh to ensure that their space is adequate for your scenario (if your application requires a wall, you want to ensure that at least one wall has been scanned before exiting the scanning phase).

> Usually the raw spatial mapping meshes are not very useful to an application that will interact with the environment (physics, navigation, etc). That's where processing of the mesh is important. The Spatial Understanding and PlaneFinding features of the HoloToolkit can help here. The level of processing required (if any) is unique to each application. Ideally, if you have a lot of processing, you will save the resulting processed mesh off and then load it at the beginning of future sessions. If the reload is successful, then rescanning won't be necessary. However, you still need to support a scanning phase, in case the user has moved to a new location and loading the saved processed mesh fails.

> Overall, how much scanning and processing is required is very much dependent on your application's design. Some applications won't use spatial mapping at all, so this won't be an issue. Others, like the 'Origami' tutorial, need to move/set an object on real-world surfaces that might be changing (like people), so constantly scanning the environment while using the raw mesh data is adequate (these apps have no built-in 'scanning' phase, as they just keep the SpatialMappingObserver running during the entire application). While other applications, like 'RoboRaid' 'Conker' and 'Fragments', have a dedicated scan time to ensure that they get quality meshes before running expensive processing of the spatial data (to place objects in sensible locations, build AI navigation paths, determine physics properties for various objects in the room, etc.). When you have a dedicated scanning phase, you can keep the user from getting bored (if you create a unique visual for the mesh, users will be happy to keep scanning their environment) as they wait for processing to complete and the rest of the application to begin.


## Un-load system-global space data
### Trial 1. Comment out SetVolumeAsAxisAlignedBox
```cs
// SpatialMappingObserver.cs
public void StartObserving()
{
   if (observer == null)
   {
       observer = new SurfaceObserver();
       // observer.SetVolumeAsAxisAlignedBox(Vector3.zero, Extents);
   }
   ...
}
```
#### Result
Doesn't run spatial mapping at all.
#### Why?
Check [Unity documentation](https://docs.unity3d.com/ScriptReference/VR.WSA.SurfaceObserver.SetVolumeAsAxisAlignedBox.html):
> This method sets the observation volume as an axis aligned box at the requested location. Successive calls can be used to reshape the observation volume and/or to move it in the scene as needed. Extents are the distance from the center of the box to its edges along each axis. Very large observation volumes will increase overhead of calling SurfaceObserver.Update as the number of observable Surfaces grows.

So no `.SetVolumeAsAxisAlignedBox()` no scanning. In our application we have set the extents as 10m.
```cs
[Tooltip("The extents of the observation volume.")]
public Vector3 Extents = Vector3.one * 10.0f;
```

### Trial 2. Test "Young Conker" ([issue](https://github.com/Microsoft/HoloToolkit-Unity/issues/659))
I tested with "Young Conker" again and it seems like even that game is using system-global space data BUT it can somehow smartly **select specific parts of the data.**

Here's how I tested:
1. Run "Young Conker"
2. Scan new area and save it.
3. Repeat step 1 & 2 few more times. Check system-global space size. They get larger and larger in each iteration.
4. Now delete your system-global space from `Settings`.
5. Run "Young Conker"
6. Try to load saved spaces.
7. None of the saved spaces will be usable.

Here's my understanding about spatial mapping logic in HoloLens:
* Every app uses system-global space which is shared by all other apps on the HL.
* All scanned data within an app will be shared by all other apps on the HL.
* Space data cannot be deleted programmatically.
* An app can ***save*** space like "Young Conker" but it's just referring to the system global space.

Am I understanding correctly?


## Plan from now on.
Let's not work against the framework. Don't try to delete space data but delete mesh objects. It is the mesh objects that is heavy for the program. Keep track of Surface IDs and call `RequestMeshAsync()` for only the ones you need.

Good luck!
